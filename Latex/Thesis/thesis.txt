Compressive Sensing in Video Encoding

Brian Azizi
Department of Physics
Centre for Scientific Computing
University of Cambridge

This dissertation is submitted for the degree of
Master of Philosophy

Selwyn College

July 2016

I would like to dedicate this thesis to my loving parents ...

Declaration

I hereby declare that except where specific reference is made to the work of others, the
contents of this dissertation are original and have not been submitted in whole or in part
for consideration for any other degree or qualification in this, or any other University. This
dissertation is the result of my own work and includes nothing which is the outcome of
work done in collaboration, except where specifically indicated in the text. This dissertation
contains less than 65,000 words including appendices, bibliography, footnotes, tables and
equations and has less than 150 figures.
Brian Azizi
July 2016

Acknowledgements

And I would like to acknowledge ...

Abstract

This is where you write your abstract ...

Table of contents
List of figures

xiii

List of tables

xv

Nomenclature

xvii

1

Introduction

1

2

Compressive Sensing

3

3

Wavelets

5

3.1

Discrete Cosine Transform . . . . . . . . . . . . . . . . . . . . . . . . . .

5

3.2

Wavelet transforms . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

5

3.2.1

Haar wavelets . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

5

3.2.2

Daubechies Wavelets . . . . . . . . . . . . . . . . . . . . . . . . .

6

Forming the basis matrix . . . . . . . . . . . . . . . . . . . . . . . . . . .

6

3.3
4

Sparse Bayesian Learning

7

5

Design of the Multi-Scale Cascade of Estimations Algorithm

9

5.1

9

6

Interpolator . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

11

6.1

Haar basis functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

11

6.1.1

1D Haar wavelet transform . . . . . . . . . . . . . . . . . . . . . .

11

6.1.2

2D Haar wavelet transform . . . . . . . . . . . . . . . . . . . . . .

12

6.1.3
7

Implementation Details and Code optimization

3D Haar wavelet transform . . . . . . . . . . . . . . . . . . . . . .

13

Results

15

xii
8

Table of contents
Conclusion

References

17
19

List of figures
2.1

Example of a signal pair x (left) and y (right). We wish to reconstruct x from y .

3

3.1

Original image x (left) and its Haar basis transformation w (right). See next
chapter for more details on Haar wavelets. . . . . . . . . . . . . . . . . . .

6

ˆ
Corrupted signal y (left) and reconstructed signal x (right) using a cascade of
3 RVMs with Haar basis functions (see [3]). . . . . . . . . . . . . . . . . .

8

4.1

7.1
7.2

Sample frame from corrupted video (left) and the reconstructed video (right) 16
Sample frame from corrupted video (left) and the reconstructed video (right) 16

List of tables

Nomenclature
Roman Symbols
w

RVM weights vector

Chapter 1
Introduction
There are three parts: A signal processing framework called Compressive Sensing (CS), a
pre-processing step in form of a basis transformation based on discrete wavelet transforms
and a Machine Learning algorithm called Sparse Bayesian Learning.

Background

Chapter 2
Compressive Sensing
This section is based on [3]. The problem to be solved can be formulated as follows: Let
x ∈ RN be a signal of interest. We do not measure x directly and it is thus unknown. Instead,
we have a measurement y ∈ RM , with M << N, from which we want to reconstruct x . The
signals x and y are related as follows:
Ωx = y

(2.1)

where Ω is a known M × N matrix referred to as the sensing matrix.
For example, in [3], the signal of interest x is an image, so that N is equal to the total
number of pixels in the image and xi is equal to the intensity of the corresponding pixel.
However, we imagine that we have only access to a corrupted version of x in which random
pixel values have been deleted. This is our measurement y . See Figure ?? for an example.
The sensing matrix Ω corresponding to this scenario is obtained by taking the N × N identity
matrix and deleting the rows that correspond to the missing entries in x .

Fig. 2.1 Example of a signal pair x (left) and y (right). We wish to reconstruct x from y .

4

Compressive Sensing

Compressive Sensing (CS) is a collection of signal processing techniques that allow for efficient reconstruction (and indeed aquisition) of such signals by solving the underdetermined
system (2.1).
Of course, there are infinitely many solutions to an underdetermined system. In the CS
ˆ
framework, we seek to find a solution x that is sparsest in some domain. By that, we mean
ˆ
ˆ
that we want to find x that satisfies (2.1), such that there exists a basis transformation of x in
which it has the smallest number of nonzero entries.
More concretely, we assume there exists a domain in which the desired signal x is sparse.
I.e. there exists a N × N basis matrix Ψ such that x = Ψ w and w is sparse.
The CS problem can then be expressed as follows:
w
min ||w ||0

subject to

ΩΨw = y

where ||.|| denotes the l0 norm, i.e. the number of nonzero components.
For a more detailed review of the CS framework, see [1].

(2.2)

Chapter 3
Wavelets
In this chapter, we will introduce wavelet functions and the Discrete Wavelet Transform
(DWT). The DWT allows us to transform our signal into a new basis in which it is sparse.
x = Ψw

(3.1)

that takes the dense signal x and sends it into a domain in which its transformation w = Ψ T x
is sparse.

3.1

Discrete Cosine Transform

An aside on the DCT. Used in old JPEG standard (ref). Formulae. Interpretations. Pictures.
However, before we discuss wavelets, we will briefly introduce the Discrete Cosine Transform
(DCT)

3.2
3.2.1

Wavelet transforms
Haar wavelets

Finding a set of basis functions Ψ that achieve such a transformation lies at the heart of many
lossy compression techniques. For instance, in image processing the JPEG 2000 standard is
a widely used lossy compression technique that relies on this principle. The original image x
is transformed into w using the so-called Discrete Cosine Transform. The basis matrix Ψ is
orthogonal, so x and w have the same l2 norm. In the original signal x the length is spread
across many of its coefficients. On the other hand, most of the length of w is concentrated
in a few of its coefficients. A large fraction of the entries in w are very close to zero. By

6

Wavelets

Fig. 3.1 Original image x (left) and its Haar basis transformation w (right). See next chapter
for more details on Haar wavelets.
deleting these entries in w and only storing the non-zero coefficients (and the corresponding
ˆ
basis functions), we can obtain a compressed version w . This allows us to significantly
reduce the amount of data that needs to be stored without affecting the visual quality in the
ˆ
ˆ
reconstructed image x = Ψ w .
It is important to note here that the choice of basis functions Ψ typically has a significant
effect on the performance of the reconstruction algorithms.
The simplest wavelet basis transformation is based on the Haar wavelets. Figure ??
vizualises a basis transformation of the original image x to w . This example uses a Haar
wavelet basis at the first scale. We will explain the Haar wavelet transformations of images
and videos in more detail in the next chapter. Dark areas correspond to small coefficients.
Note that most entries in w are near zero. In practice, we approximate these entries as zero
and treat w as sparse.

3.2.2

Daubechies Wavelets

Intuition. Where do the coeffs come from. Matrices. Boundary conditions.

3.3

Forming the basis matrix

1D, 2D, 3D case. Different scales
For a deeper introduction into wavelets see [4]. For more information on wavelet
compression techniques, see [2].

Chapter 4
Sparse Bayesian Learning
This chapter introduces the Sparse Bayesian Learning Model
The RVM is a regression technique. We model the relationship between y and x by
yi = w T ψ (xi ) + εi

(4.1)

where ψ(xi ) is the ith column of Ψ and the εi are independent noise variables drawn from a
zero-mean Gaussian distribution N (o, σ 2 ).
The model uses the available measurements {(x1 , y1 ), . . . , (xM , yM )} as training data to
train the model in a Bayesian framework. The result of training the RVM is a posterior
distribution for the unknown vector of coefficients w. A special feature of the RVM is that
the posterior mean µ of w is often very sparse.
In order to reconstruct the image, we use the estimated posterior mean to “predict” what
a pixel value y∗ should be at a location x∗ in which information was missing:
y∗ = wT ψ (x∗ )

(4.2)

Apart from achieving sparse solutions, one further desirable feature of the RVM is that
the model provides error bars for its predictions. This is used in [3] to construct a multi-scale
cascade of RVM estimations and achieve significant performance boosts.
An example of this can be seen in Figure 4.1.
For details on the RVM and its implementation see [3, 5, 6].

8

Sparse Bayesian Learning

ˆ
Fig. 4.1 Corrupted signal y (left) and reconstructed signal x (right) using a cascade of 3
RVMs with Haar basis functions (see [3]).

Chapter 5
Design of the Multi-Scale Cascade of
Estimations Algorithm
Bringing all building blocks together. Description and explanation of the algorithm
So far, we have not addressed the central question: How do we solve the compressive
sensing problem (2.2)? Various deterministic approaches have been developed in recent
years. See [3] for an overview.
In the MPhil project, we will employ a probabilistic technique based on Sparse Bayesian
Learning. In particular, we will use the Relevance Vector Machine (RVM) [5, 6] to reconstruct
w from the measurements y . Following that, we obtain a reconstructed version of the desired
signal x by pre-multiplying w by Ψ to obtain the desired signal.

5.1

Interpolator

We use a sensing matrix Ω that acts as signal mask. That is, we obtain the N × M matrix
Ω by taking the M × M identity matrix I M and deleting (M − N) rows. This corresponds
to a subsampled signal in which we only measured N pixel values. For this specific class
of sensing matrices, the problem of reconstructing the original signal is also known as
interpolation.

Chapter 6
Implementation Details and Code
optimization
This chapter gives a brief description of the current state of our implementation of the 3D
signal reconstructer.

6.1

Haar basis functions

y
Ψ
The RVM takes as input a target vector (y ) and a basis matrix (Ψ ). In this respect, it is
agnostic about whether the signal is an image or video or of some other type alltogether.
Most of this information is encoded in the basis matrix Ψ . It is therefore important, and often
challenging, to select a good set of basis functions.
Our current implementation uses 3-dimensional Haar wavelet basis functions. I will show
how the basis matrix Ψ is constructed by briefly describing how the discrete Haar wavelet
transform is performed on 1D, 2D and finally on 3D signals.

6.1.1

1D Haar wavelet transform

Consider a 1-dimensional signal s = {s1 , . . . , sr } ∈ Rr (r for “rows”), where, for simplicity,
we assume that r is a power of 2. The Haar wavelet transform can be performed at various
resolution scales. The transform at the first scale is given by:
1
ˆ
s = {s1 , . . . , sr } → √ {s1 + s2 , s3 + s4 , . . . , sr−1 + sr , s1 − s2 , . . . , sr−1 − sr } = s (1)
2
The first half of the signal is replaced by scaled averages of adjacent elements and the second
half is replaced by scaled differences of adjacent elements. By performing this transform

12

Implementation Details and Code optimization

ˆ
again on the first half of s (1) while keeping the second half fixed, we get the Haar wavelet
ˆ
ˆ
transform at the second scale s (2) . To get the third scale transform s (3) , we perform the
(2)
ˆ
initial transform on the first quarter of s while keeping the rest of the signal fixed. We may
continue this process until we reach the ith scale, where 2i = r.
ˆ
From here on, we will only consider the first scale transform s (1) and we will omit the (1)
superscript. We can express the transform as a multiplication by an orthogonal r × r matrix
W given by
Φr
W=
(6.1)
Ψr
where Φr and Ψr are (r/2) × r matrices1 given by


1

1 0
Φr = √  .
2 .
.

1
0
.
.
.

0
1
.
.
.

0 ···
1 ···
. ..
.
.
.

0
0
.
.
.


0

0
.
.
.

0 0 0 0 ··· 1 1
and



1 −1 0 0 · · · 0 0


1 0 0 1 −1 · · · 0 0 
. . . .

Ψr = √ 
. . . . ... . . 
. . 
2 . . . .
. .
0 0 0 0 · · · 1 −1

In the signal processing literature, Φr is referred to as a low pass filter, while Ψr is
referred to as a high pass filter. Φr outputs an average of the signal and Ψr outputs the details
of the signal.

6.1.2

2D Haar wavelet transform

Let A ∈ Rr×c be a 2-dimensional signal (e.g. an image). For simplicity, we will assume that
both r and c are powers of 2 (though not necessarily equal).
ˆ
It is simple to obtain A’s Haar wavelet transform A at the first scale. This is done by first
applying the 1-dimensional transform individually to each column of A to obtain a temporary
ˆ
matrix Atemp . Next, we apply the 1-dimensional haar wavelet transform individually to each
ˆ
ˆ
row of Atemp to obtain A.
1 Note

that the matrix Ψr used here is different to the matrix Ψ that was used in the previous chapter (which
corresponds to W T here).

13

6.1 Haar basis functions
We can again express the transform as a multiplication of matrices:
Φr
ˆ
A=
A ΦT ΨT
c
c
Ψr

(6.2)

where Φr and Ψr are as before and Φc and Ψc are of similar form but each have dimensions
(c/2) × c. This is the transform that was used to generate the RHS of Figure ??. We note
that the high-pass filters essentially detect edges of various orientations in the image.
However, as it currently stands, we cannot use this form of the basis transformation for
the reconstruction algorithm. Recall that the RVM requires a vector of measurements as
opposed to a matrix and also that it requires a single basis matrix, not a basis transform as
given in (6.2).
To do this, we store the 2-dimensional signal A as a long column vector a of length rc by
pasting the individual columns of A one after another. The basis transformation of a can then
be expressed as
ˆ
a = Wa
where W is a rc × rc matrix given by



Φc ⊗ Φr
Φ ⊗ Ψ 
 c
r
W =

Ψc ⊗ Φr 
Ψc ⊗ Ψr
The symbol ⊗ denotes the Kronecker product. The kronecker product P ⊗ Q between
matrices P and Q with dimensions mP × nP and mQ × nQ , respectively, is defined to be the
block matrix


p1,1 Q p1,2 Q · · · p1,nP Q


 p2,1 Q p2,2 Q · · · p2,nP Q 
 .

.
.
...
 .

.
.
.
.
 .

pmP ,1 Q pmP ,2 Q · · · pmP ,nP Q
of size mP mQ × nP nQ .

6.1.3

3D Haar wavelet transform

Let V ∈ Rr×c×s be a 3-dimensional signal such as a video. V has r rows, c columns and s
slices, and we assume that r, c and s are all powers of 2. We may visualize V as a “volume”
with 2 spacial dimensions and one time dimension corresponding to frames of the video.

14

Implementation Details and Code optimization

ˆ
To obtain the Haar wavelet transform V of V , we first perform the 1-dimensional transform
ˆ
individually on each column in every slice of V to get Vtemp1 . We then perform the 1D
ˆ
ˆ
transform on every row in every slice of Vtemp1 to get Vtemp2 . Finally, we perform the 1D
ˆ
transform across the slices for every row and column to get V .
However, like in the 2-dimensional case, we need to be able to pass a single vector of
coefficients and a single basis matrix to the RVM. To do this, we vectorize V as follows.
First, we vectorize each individual slice of V as before in the 2D case. Then, we stack all
these vectors on top each other to get one very long column vector v of length rcs. The Haar
wavelet transform is given by
ˆ
v = Wv
where




Φs ⊗ Φc ⊗ Φr


 Φs ⊗ Φc ⊗ Ψr 


 Φs ⊗ Ψc ⊗ Φr 


Φ ⊗ Ψ ⊗ Ψ 
 s
c
r
W =

 Ψs ⊗ Φc ⊗ Φr 


Ψ ⊗ Φ ⊗ Ψ 
c
r
 s


Ψs ⊗ Ψc ⊗ Φr 
Ψs ⊗ Ψc ⊗ Ψr

Comparing notation to the previous chapter, what we refer to as W here is the transpose of
ˆ
what was previously denoted as Ψ. And since v = W T v , we see that v corresponds to what
was previously called x.

Chapter 7
Results
We have obtained some results with our current implementation. The implementation uses
the Haar wavelet transform at the first scale.
Our example video has a resolution of 128 by 128 pixels and consists of a total of 64
frames. Thus, r = 128, c = 128 and s = 64. Note that even for such a relatively small sample,
the size of the basis matrix Ψ is (128 ∗ 128 ∗ 64) × (128 ∗ 128 ∗ 64) = 1048576 × 1048576.
Even in single precision, storing this matrix would require around 4 terrabytes.
For this reason, we have split the original input signal into 8 × 8 × 8 blocks and perform
the algorithm on the individual blocks.
In Figures 3.1 and 3.2, we have included a sample frame from the corrupted test video
and the same frame after reconstruction.
In Figure 3.1, we corrupted the video by deleting 30% of the pixel values in the first
frame and deleting the same pixel values in each subsequent frame (so the same pixels are
missing in each frame). Figure 3.2 uses the same corruption scheme but we deleted 50%
rather than 30% of pixel values.
These initial results are promising, though clearly there are still improvements to be
made.

16

Results

Fig. 7.1 Sample frame from corrupted video (left) and the reconstructed video (right)

Fig. 7.2 Sample frame from corrupted video (left) and the reconstructed video (right)

Chapter 8
Conclusion

References
[1] Candès, E. J. and Wakin, M. B. (2008). An introduction to compressive sampling. Signal
Processing Magazine, IEEE, 25(2):21–30.
[2] DeVore, R. A., Jawerth, B., and Lucier, B. J. (1992). Image compression through wavelet
transform coding. Information Theory, IEEE Transactions on, 38(2):719–746.
[3] Pilikos, G. (2014). Signal reconstruction using compressive sensing. MPhil thesis,
University of Cambridge.
[4] Stollnitz, E. J., DeRose, T. D., and Salesin, D. H. (1995). Wavelets for computer graphics:
a primer. 1. Computer Graphics and Applications, IEEE, 15(3):76–84.
[5] Tipping, M. E. (2001). Sparse bayesian learning and the relevance vector machine. The
journal of machine learning research, 1:211–244.
[6] Tipping, M. E., Faul, A. C., et al. (2003). Fast marginal likelihood maximisation for
sparse bayesian models. In AISTATS.

